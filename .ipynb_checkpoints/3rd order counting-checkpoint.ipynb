{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uniparse import Vocabulary\n",
    "from uniparse.dataprovider import batch_by_buckets\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from uniparse import Model, Vocabulary\n",
    "\n",
    "from uniparse.callbacks import ModelSaveCallback\n",
    "from uniparse.dataprovider import batch_by_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uniparse intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()\n",
    "samples = vocab._read_conll(\"../data/ptb_conllu/train.conllu\", tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.choice(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'DET', 'ADJ', 'NOUN', 'NOUN']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[2][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 'det',\n",
       " 'amod',\n",
       " 'nmod:tmod',\n",
       " 'compound',\n",
       " 'nsubjpass',\n",
       " 'auxpass',\n",
       " 'acl:relcl',\n",
       " 'case',\n",
       " 'det',\n",
       " 'amod',\n",
       " 'nmod',\n",
       " 'cc',\n",
       " 'nsubj',\n",
       " 'conj',\n",
       " 'punct',\n",
       " 'punct',\n",
       " 'discourse',\n",
       " 'dep',\n",
       " 'punct',\n",
       " 'nsubj',\n",
       " 'punct',\n",
       " 'nsubj',\n",
       " 'aux',\n",
       " 'ccomp',\n",
       " 'dobj',\n",
       " 'case',\n",
       " 'nmod',\n",
       " 'cc',\n",
       " 'compound',\n",
       " 'conj',\n",
       " 'punct',\n",
       " 'punct',\n",
       " 'nsubj',\n",
       " 'root',\n",
       " 'nsubj',\n",
       " 'aux',\n",
       " 'ccomp',\n",
       " 'compound:prt',\n",
       " 'cc',\n",
       " 'conj',\n",
       " 'punct',\n",
       " 'punct',\n",
       " 'xcomp',\n",
       " 'dobj',\n",
       " 'punct',\n",
       " 'dobj',\n",
       " 'punct',\n",
       " 'advmod',\n",
       " 'aux',\n",
       " 'neg',\n",
       " 'nsubj',\n",
       " 'parataxis',\n",
       " 'dobj',\n",
       " 'cc',\n",
       " 'conj',\n",
       " 'nmod:poss',\n",
       " 'amod',\n",
       " 'amod',\n",
       " 'compound',\n",
       " 'compound',\n",
       " 'dobj',\n",
       " 'punct']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract parent -> head -> modifier from treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def count_3rd_order_sets(treebank_file, vocab):\n",
    "    samples = vocab._read_conll(treebank_file, tokenize=False)\n",
    "    counter = Counter()\n",
    "    for sample in samples:\n",
    "        extract_3O_paths(sample[3], sample[4], counter)\n",
    "        \n",
    "    factors = [{\"afactor\":\"%s->%s->%s\"%k, \"count\":v} for k,v in counter.items()]\n",
    "    df = pd.DataFrame.from_dict(factors).sort_values(\"count\", ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_3O_paths(tree, tags, counter, root_token=\"<root>\"):    \n",
    "    for m, h in enumerate(tree):\n",
    "        p = tree[h]\n",
    "        parent_tag, head_tag, modifier_tag = [tags[i] if i >= 0 else tags[0] for i in [p, h, m]]\n",
    "        parent_tag, head_tag, modifier_tag = [t if t != 1 else root_token for t in [parent_tag, head_tag, modifier_tag]]\n",
    "        counter.update([(parent_tag, head_tag, modifier_tag)])\n",
    "\n",
    "def factor_to_str(t):\n",
    "    return \"->\".join(t)\n",
    "\n",
    "def get_factor_weights(dataframe):\n",
    "    dataset = []\n",
    "    factor_map = defaultdict(int)\n",
    "    for i, row in dataframe.iterrows():\n",
    "        factor = row[\"afactor\"]\n",
    "        factor_map[i] = factor\n",
    "        for _ in range(row[\"count\"]):\n",
    "            dataset.append(i)\n",
    "    classes = np.unique(dataset)\n",
    "    weights = class_weight.compute_class_weight(\"balanced\", classes, dataset)\n",
    "    return {factor_map[c]:w for c,w in zip(classes,weights)}\n",
    "\n",
    "def batch_to_weights(sample, factor_weights, tag_map):\n",
    "    (words, tags), (trees, labels) = sample\n",
    "    # batch :: (b, n)\n",
    "    output = np.zeros(trees.shape)\n",
    "    for b, tree in enumerate(trees):\n",
    "        for m, h in enumerate(tree):\n",
    "            p = tree[h]\n",
    "            parent_tag, head_tag, modifier_tag = [\n",
    "                tags[b, i] if i >= 0 else tags[b, 0]\n",
    "                for i in [p, h, m]\n",
    "            ]\n",
    "            factor_ = (parent_tag, head_tag, modifier_tag)\n",
    "            factor = [tag_map[e] for e in factor_]\n",
    "            factor = factor_to_str(factor)\n",
    "            try:\n",
    "                output[b, m] = factor_weights[factor]\n",
    "            except:\n",
    "                print(factor_)\n",
    "                raise\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_df = count_3rd_order_sets(\"../data/ptb_conllu/train.conllu\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5479, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afactor</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;root&gt;-&gt;root-&gt;punct</td>\n",
       "      <td>66432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>&lt;root&gt;-&gt;&lt;root&gt;-&gt;root</td>\n",
       "      <td>37977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>root-&gt;&lt;root&gt;-&gt;&lt;root&gt;</td>\n",
       "      <td>37660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>&lt;root&gt;-&gt;root-&gt;nsubj</td>\n",
       "      <td>32967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>root-&gt;nmod-&gt;case</td>\n",
       "      <td>17664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 afactor  count\n",
       "26   <root>->root->punct  66432\n",
       "38  <root>-><root>->root  37977\n",
       "0   root-><root>-><root>  37660\n",
       "41   <root>->root->nsubj  32967\n",
       "1       root->nmod->case  17664"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ptb_df.shape)\n",
    "ptb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ptb_df[\"count\"] == 1).sum()/ptb_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_df.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ptb_df[\"count\"] < 10\n",
    "x.astype(int).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UD EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_en_df = count_3rd_order_sets(\"../data/en_ewt-ud-train.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ud_en_df.shape)\n",
    "ud_en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_factor_weights = get_factor_weights(ud_en_df)\n",
    "ud_factor_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets test it all out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()\n",
    "vocab.fit(\"../data/en_ewt-ud-train.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vocab.tokenize_conll(\"../data/en_ewt-ud-train.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uniparse.dataprovider import batch_by_buckets\n",
    "X = batch_by_buckets(X, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, samples = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_weights = batch_to_weights(samples[0], ud_factor_weights, vocab.tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_sample_weights = [batch_to_weights(samples[0], ud_factor_weights, vocab.tag2id) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_sample_weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat = [(x+(w,),y)for (x,y), w in zip(X[1], ud_sample_weights)]\n",
    "words, tags, weights = X_hat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.shape, weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets do it from the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uniparse.models.dynet.syntax_att import Parser\n",
    "\n",
    "def train(train_file, dev_file, test_file, n_epochs, parameter_file, vocab_file, model_class):\n",
    "    \"\"\"Training procedure.\"\"\"\n",
    "    vocab = Vocabulary()\n",
    "    vocab = vocab.fit(train_file)\n",
    "    \n",
    "    # \"../data/en_ewt-ud-train.conllu\"\n",
    "    train_file_df = count_3rd_order_sets(train_file, vocab)\n",
    "    \n",
    "    # save vocab for reproducability later\n",
    "    if vocab_file:\n",
    "        print(\"> saving vocab to\", vocab_file)\n",
    "        vocab.save(vocab_file)\n",
    "\n",
    "    # prep data\n",
    "    print(\">> Loading in data\")\n",
    "    train_data = vocab.tokenize_conll(train_file)\n",
    "    dev_data = vocab.tokenize_conll(dev_file)\n",
    "    test_data = vocab.tokenize_conll(test_file)\n",
    "\n",
    "    train_batches = batch_by_buckets(train_data, batch_size=32, shuffle=True)\n",
    "    dev_batches = batch_by_buckets(dev_data, batch_size=32, shuffle=True)\n",
    "    test_batches = batch_by_buckets(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    indicies, samples = train_batches\n",
    "    \n",
    "    factor_weights = get_factor_weights(train_file_df)\n",
    "\n",
    "    label_weights = [batch_to_weights(sample, factor_weights, vocab._rel2id) for sample in samples]\n",
    "    X_hat = [(x+(w,),y) for (x,y), w in zip(train_batches[1], label_weights)]\n",
    "    train_batches = (indicies, X_hat)\n",
    "\n",
    "    model = model_class(vocab)\n",
    "\n",
    "    save_callback = ModelSaveCallback(parameter_file)\n",
    "    callbacks = [save_callback]\n",
    "\n",
    "    # prep params\n",
    "    parser = Model(model, optimizer=\"adam\", vocab=vocab)\n",
    "\n",
    "    parser.train(train_batches, dev_file, dev_batches, epochs=n_epochs, callbacks=callbacks, verbose=True)\n",
    "    parser.load_from_file(parameter_file)\n",
    "\n",
    "    metrics = parser.evaluate(test_file, test_batches, delete_output=False)\n",
    "    test_UAS = metrics[\"nopunct_uas\"]\n",
    "    test_LAS = metrics[\"nopunct_las\"]\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "    print()\n",
    "    print(\">>> Model maxed on dev at epoch\", save_callback.best_epoch)\n",
    "    print(\">>> Test score:\", test_UAS, test_LAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> saving vocab to model.vocab\n",
      ">> Loading in data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4e4a74a492a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mDEV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/en_ewt-ud-dev.conllu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTEST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/en_ewt-ud-test.conllu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.vocab\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-09ab3cc33af7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_file, dev_file, test_file, n_epochs, parameter_file, vocab_file, model_class)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mfactor_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_factor_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mlabel_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_to_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel2id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindicies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-09ab3cc33af7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mfactor_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_factor_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mlabel_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_to_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel2id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindicies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cd9e40d534dd>\u001b[0m in \u001b[0;36mbatch_to_weights\u001b[0;34m(sample, factor_weights, tag_map)\u001b[0m\n\u001b[1;32m     47\u001b[0m             ]\n\u001b[1;32m     48\u001b[0m             \u001b[0mfactor_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparent_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodifier_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtag_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactor_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactor_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cd9e40d534dd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m             ]\n\u001b[1;32m     48\u001b[0m             \u001b[0mfactor_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparent_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodifier_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtag_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactor_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactor_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "TRAIN = \"../data/en_ewt-ud-train.conllu\"\n",
    "DEV = \"../data/en_ewt-ud-dev.conllu\"\n",
    "TEST = \"../data/en_ewt-ud-test.conllu\"\n",
    "train(TRAIN, DEV, TEST, 30, \"model.params\", \"model.vocab\", Parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
